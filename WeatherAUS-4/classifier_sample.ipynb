{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A sample of using the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing the modules and setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom utilities for working with weather data\n",
    "import utils_weather as we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# List of classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Metrics\n",
    "import sklearn.metrics as metric\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "\n",
    "rain_score = make_scorer(fbeta_score, beta=2, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['logreg-0', 'logreg-1', 'logreg-2', 'knn-0', 'knn-1', 'knn-2', 'knn-3', 'svc-0', 'tree-0', 'tree-1', 'tree-2', 'forest-0', 'forest-1', 'forest-2', 'forest-3', 'mpl-0', 'mpl-1'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we.get_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       " 'logreg__penalty': ['l2'],\n",
       " 'logreg__solver': ['liblinear', 'newton-cg', 'lbfgs']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we.get_search(\"logreg-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'logreg': LogisticRegression(max_iter=10000),\n",
    "    'mpl': MLPClassifier(max_iter=400),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'svc': SVC(),\n",
    "    'tree': DecisionTreeClassifier(),\n",
    "    'forest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "SCALER = StandardScaler()\n",
    "ENCODER = OneHotEncoder()\n",
    "\n",
    "MODEL_TYPE = \"logreg\"\n",
    "MODEL = models.get(MODEL_TYPE)\n",
    "\n",
    "SEARCH_PARAM = we.get_search(\"logreg-0\")\n",
    "CV_PARAM = 3  # GridSearchCV(cv=)\n",
    "VB_PARAM = 4  # GridSearchCV(verbose=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns selection: ['origin', 'small', 'big', 'var-1', 'var-2']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns selection:\", we.get_columns())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Location', 'MinTemp', 'MaxTemp', 'Diff_Temp', 'Temp9am', 'Temp3pm', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir_Change', 'WindSpeed_Diff', 'WindDir9am', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Humidity_Diff', 'Pressure9am', 'Pressure3pm', 'Pressure_Diff', 'Cloud9am', 'Cloud3pm', 'RainToday', 'RainTomorrow']\n"
     ]
    }
   ],
   "source": [
    "COLUMNS = 'big'\n",
    "print(we.get_columns(COLUMNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# FutureWarning: is_categorical is deprecated and will be removed\n",
    "# in a future version.  Use is_categorical_dtype instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading raw data, cleaning and splitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/current_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     0.776878\n",
       "Yes    0.223122\n",
       "Name: RainTomorrow, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['RainTomorrow'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2684"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['RainTomorrow'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = raw_data.dropna(subset=['RainTomorrow'])\n",
    "raw_data['RainTomorrow'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = we.get_data(raw_data, columns=COLUMNS, target='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116219, 27)\n",
      "(116219,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Diff_Temp</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>...</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Humidity_Diff</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Pressure_Diff</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>RainToday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>December</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>December</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>December</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>12.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>December</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>December</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date Location  MinTemp  MaxTemp  Diff_Temp  Temp9am  Temp3pm  Rainfall  \\\n",
       "0  December   Albury     13.4     22.9        9.5     16.9     21.8       0.6   \n",
       "1  December   Albury      7.4     25.1       17.7     17.2     24.3       0.0   \n",
       "2  December   Albury     12.9     25.7       12.8     21.0     23.2       0.0   \n",
       "3  December   Albury      9.2     28.0       18.8     18.1     26.5       0.0   \n",
       "4  December   Albury     17.5     32.3       14.8     17.8     29.7       1.0   \n",
       "\n",
       "   Evaporation  Sunshine  ... WindSpeed3pm  Humidity9am  Humidity3pm  \\\n",
       "0          NaN       NaN  ...         24.0         71.0         22.0   \n",
       "1          NaN       NaN  ...         22.0         44.0         25.0   \n",
       "2          NaN       NaN  ...         26.0         38.0         30.0   \n",
       "3          NaN       NaN  ...          9.0         45.0         16.0   \n",
       "4          NaN       NaN  ...         20.0         82.0         33.0   \n",
       "\n",
       "   Humidity_Diff Pressure9am Pressure3pm  Pressure_Diff  Cloud9am  Cloud3pm  \\\n",
       "0           49.0      1007.7      1007.1            0.6       8.0       NaN   \n",
       "1           19.0      1010.6      1007.8            2.8       NaN       NaN   \n",
       "2            8.0      1007.6      1008.7            1.1       NaN       2.0   \n",
       "3           29.0      1017.6      1012.8            4.8       NaN       NaN   \n",
       "4           49.0      1010.8      1006.0            4.8       7.0       8.0   \n",
       "\n",
       "   RainToday  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87164, 27)\n",
      "(29055, 27)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Features preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WindDir_Change', 'RainToday']\n",
      "['MinTemp', 'MaxTemp', 'Diff_Temp', 'Temp9am', 'Temp3pm', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed_Diff', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Humidity_Diff', 'Pressure9am', 'Pressure3pm', 'Pressure_Diff', 'Cloud9am', 'Cloud3pm']\n",
      "['Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm']\n"
     ]
    }
   ],
   "source": [
    "bin_features, num_features, cat_features = we.get_3group_features(X_train)\n",
    "print(bin_features)\n",
    "print(num_features)\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features.remove('Rainfall')\n",
    "# num_features.remove('Evaporation')\n",
    "# num_features.remove('Sunshine')\n",
    "# cat_features.remove('Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', SCALER)\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', ENCODER)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "        ('bin', binary_transformer, bin_features),\n",
    "        ('num', numeric_transformer, num_features),\n",
    "        ('cat', categorical_transformer, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        (MODEL_TYPE, MODEL)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Target preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87164,)\n",
      "(29055,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_imputer = SimpleImputer(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(strategy='most_frequent')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_imputer.fit(y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = target_imputer.transform(\n",
    "                    y_train.values.reshape(-1, 1)\n",
    "                ).ravel()\n",
    "y_test = target_imputer.transform(\n",
    "                    y_test.values.reshape(-1, 1)\n",
    "                ).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Modelling and search optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "[CV] logreg__C=0.001 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... logreg__C=0.001, score=0.463, total=   4.5s\n",
      "[CV] logreg__C=0.001 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... logreg__C=0.001, score=0.475, total=   4.3s\n",
      "[CV] logreg__C=0.001 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... logreg__C=0.001, score=0.470, total=   4.3s\n",
      "[CV] logreg__C=0.01 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   13.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... logreg__C=0.01, score=0.503, total=   4.9s\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] ...................... logreg__C=0.01, score=0.512, total=   5.4s\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] ...................... logreg__C=0.01, score=0.512, total=   5.1s\n",
      "[CV] logreg__C=0.1 ...................................................\n",
      "[CV] ....................... logreg__C=0.1, score=0.516, total=   6.2s\n",
      "[CV] logreg__C=0.1 ...................................................\n",
      "[CV] ....................... logreg__C=0.1, score=0.522, total=   6.4s\n",
      "[CV] logreg__C=0.1 ...................................................\n",
      "[CV] ....................... logreg__C=0.1, score=0.522, total=   6.8s\n",
      "[CV] logreg__C=1 .....................................................\n",
      "[CV] ......................... logreg__C=1, score=0.517, total=   7.2s\n",
      "[CV] logreg__C=1 .....................................................\n",
      "[CV] ......................... logreg__C=1, score=0.522, total=   8.1s\n",
      "[CV] logreg__C=1 .....................................................\n",
      "[CV] ......................... logreg__C=1, score=0.523, total=   7.7s\n",
      "[CV] logreg__C=10 ....................................................\n",
      "[CV] ........................ logreg__C=10, score=0.517, total=   5.8s\n",
      "[CV] logreg__C=10 ....................................................\n",
      "[CV] ........................ logreg__C=10, score=0.522, total=   5.9s\n",
      "[CV] logreg__C=10 ....................................................\n",
      "[CV] ........................ logreg__C=10, score=0.523, total=   5.9s\n",
      "[CV] logreg__C=100 ...................................................\n",
      "[CV] ....................... logreg__C=100, score=0.517, total=   5.7s\n",
      "[CV] logreg__C=100 ...................................................\n",
      "[CV] ....................... logreg__C=100, score=0.523, total=   5.9s\n",
      "[CV] logreg__C=100 ...................................................\n",
      "[CV] ....................... logreg__C=100, score=0.523, total=   5.9s\n",
      "[CV] logreg__C=1000 ..................................................\n",
      "[CV] ...................... logreg__C=1000, score=0.517, total=   5.6s\n",
      "[CV] logreg__C=1000 ..................................................\n",
      "[CV] ...................... logreg__C=1000, score=0.523, total=   6.2s\n",
      "[CV] logreg__C=1000 ..................................................\n",
      "[CV] ...................... logreg__C=1000, score=0.523, total=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  2.1min finished\n"
     ]
    }
   ],
   "source": [
    "search = GridSearchCV(estimator=model,\n",
    "                      param_grid=SEARCH_PARAM,\n",
    "                      cv=CV_PARAM, scoring='recall',\n",
    "                      verbose=VB_PARAM)\n",
    "search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.5209):\n",
      "{'logreg__C': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter (CV score=%0.4f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.5209):\n",
      "{'logreg__C': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter (CV score=%0.4f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5149022042843837"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.recall_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9457834, 0.5149022])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.recall_score(y_test, predict, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8502495267595939"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.recall_score(y_test, predict, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7303428016071014"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.recall_score(y_test, predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8502495267595939"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.recall_score(y_test, predict, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7303428016071014"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.roc_auc_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8502495267595939"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21387,  1226],\n",
       "       [ 3125,  3317]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9457834, 0.0542166],\n",
       "       [0.4850978, 0.5149022]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diagonal Recall values True\n",
    "# Normalizes confusion matrix over the true (rows)\n",
    "metric.confusion_matrix(y_test, predict, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87251142, 0.26986573],\n",
       "       [0.12748858, 0.73013427]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diagonal Precision values True\n",
    "# Normalizes confusion matrix over the predicted (columns) conditions\n",
    "metric.confusion_matrix(y_test, predict, normalize='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73608673, 0.04219584],\n",
       "       [0.10755464, 0.11416279]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizes confusion matrix over the all the population\n",
    "metric.confusion_matrix(y_test, predict, normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.873     0.946     0.908     22613\n",
      "           1      0.730     0.515     0.604      6442\n",
      "\n",
      "    accuracy                          0.850     29055\n",
      "   macro avg      0.801     0.730     0.756     29055\n",
      "weighted avg      0.841     0.850     0.840     29055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metric.classification_report(y_test, predict, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>4.22264</td>\n",
       "      <td>4.95594</td>\n",
       "      <td>6.28939</td>\n",
       "      <td>7.48872</td>\n",
       "      <td>5.73439</td>\n",
       "      <td>5.64622</td>\n",
       "      <td>5.78246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.10964</td>\n",
       "      <td>0.172348</td>\n",
       "      <td>0.277972</td>\n",
       "      <td>0.39979</td>\n",
       "      <td>0.0416081</td>\n",
       "      <td>0.119843</td>\n",
       "      <td>0.228506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.170682</td>\n",
       "      <td>0.18507</td>\n",
       "      <td>0.191922</td>\n",
       "      <td>0.180141</td>\n",
       "      <td>0.170839</td>\n",
       "      <td>0.171218</td>\n",
       "      <td>0.173711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.000838397</td>\n",
       "      <td>0.0113325</td>\n",
       "      <td>0.0202982</td>\n",
       "      <td>0.00706408</td>\n",
       "      <td>0.00123434</td>\n",
       "      <td>0.000802355</td>\n",
       "      <td>0.0046868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_logreg__C</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'logreg__C': 0.001}</td>\n",
       "      <td>{'logreg__C': 0.01}</td>\n",
       "      <td>{'logreg__C': 0.1}</td>\n",
       "      <td>{'logreg__C': 1}</td>\n",
       "      <td>{'logreg__C': 10}</td>\n",
       "      <td>{'logreg__C': 100}</td>\n",
       "      <td>{'logreg__C': 1000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.462675</td>\n",
       "      <td>0.503001</td>\n",
       "      <td>0.51593</td>\n",
       "      <td>0.516546</td>\n",
       "      <td>0.516546</td>\n",
       "      <td>0.516546</td>\n",
       "      <td>0.516546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.475062</td>\n",
       "      <td>0.512315</td>\n",
       "      <td>0.522321</td>\n",
       "      <td>0.522475</td>\n",
       "      <td>0.522321</td>\n",
       "      <td>0.522783</td>\n",
       "      <td>0.522629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.46952</td>\n",
       "      <td>0.512007</td>\n",
       "      <td>0.521706</td>\n",
       "      <td>0.522629</td>\n",
       "      <td>0.523245</td>\n",
       "      <td>0.523245</td>\n",
       "      <td>0.523245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.469085</td>\n",
       "      <td>0.509108</td>\n",
       "      <td>0.519986</td>\n",
       "      <td>0.52055</td>\n",
       "      <td>0.520704</td>\n",
       "      <td>0.520858</td>\n",
       "      <td>0.520807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00506608</td>\n",
       "      <td>0.00431987</td>\n",
       "      <td>0.00287861</td>\n",
       "      <td>0.00283207</td>\n",
       "      <td>0.0029643</td>\n",
       "      <td>0.0030549</td>\n",
       "      <td>0.00302326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0                    1  \\\n",
       "mean_fit_time                   4.22264              4.95594   \n",
       "std_fit_time                    0.10964             0.172348   \n",
       "mean_score_time                0.170682              0.18507   \n",
       "std_score_time              0.000838397            0.0113325   \n",
       "param_logreg__C                   0.001                 0.01   \n",
       "params             {'logreg__C': 0.001}  {'logreg__C': 0.01}   \n",
       "split0_test_score              0.462675             0.503001   \n",
       "split1_test_score              0.475062             0.512315   \n",
       "split2_test_score               0.46952             0.512007   \n",
       "mean_test_score                0.469085             0.509108   \n",
       "std_test_score               0.00506608           0.00431987   \n",
       "rank_test_score                       7                    6   \n",
       "\n",
       "                                    2                 3                  4  \\\n",
       "mean_fit_time                 6.28939           7.48872            5.73439   \n",
       "std_fit_time                 0.277972           0.39979          0.0416081   \n",
       "mean_score_time              0.191922          0.180141           0.170839   \n",
       "std_score_time              0.0202982        0.00706408         0.00123434   \n",
       "param_logreg__C                   0.1                 1                 10   \n",
       "params             {'logreg__C': 0.1}  {'logreg__C': 1}  {'logreg__C': 10}   \n",
       "split0_test_score             0.51593          0.516546           0.516546   \n",
       "split1_test_score            0.522321          0.522475           0.522321   \n",
       "split2_test_score            0.521706          0.522629           0.523245   \n",
       "mean_test_score              0.519986           0.52055           0.520704   \n",
       "std_test_score             0.00287861        0.00283207          0.0029643   \n",
       "rank_test_score                     5                 4                  3   \n",
       "\n",
       "                                    5                    6  \n",
       "mean_fit_time                 5.64622              5.78246  \n",
       "std_fit_time                 0.119843             0.228506  \n",
       "mean_score_time              0.171218             0.173711  \n",
       "std_score_time            0.000802355            0.0046868  \n",
       "param_logreg__C                   100                 1000  \n",
       "params             {'logreg__C': 100}  {'logreg__C': 1000}  \n",
       "split0_test_score            0.516546             0.516546  \n",
       "split1_test_score            0.522783             0.522629  \n",
       "split2_test_score            0.523245             0.523245  \n",
       "mean_test_score              0.520858             0.520807  \n",
       "std_test_score              0.0030549           0.00302326  \n",
       "rank_test_score                     1                    2  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search.cv_results_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
